{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMn7PEbyuG2qWX6c7R0yca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ev1025/1day1commit/blob/main/%EC%BD%94%EB%93%9C%EC%8A%A4%ED%85%8C%EC%9D%B4%EC%B8%A0/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%B4%9D%EC%A0%95%EB%A6%AC_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터   \n",
        "!pip3 install hyperopt\n"
      ],
      "metadata": {
        "id": "gxkc8B26OMcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Exhaustive Gride Search\n",
        "- 범위로 설정한 모든 값으로 탐색진행\n",
        "- 하이퍼파라미터 값 3 x 3 x n(cv값) 회 진행\n",
        "- 튜닝할 하이퍼 파라미터의 수가 많을때는 사용하기 효율적이지 않다.\n"
      ],
      "metadata": {
        "id": "sVTKESaZTq44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"xgbclassifier__max_depth\" : [2,4,6]                 # \"모델__하이퍼파라미터\" : 탐색할 값 목록\n",
        "    \"xgblcassifier__colsample_bytree\" : [0.2, 0.4, 0.8],\n",
        "}"
      ],
      "metadata": {
        "id": "tFlCh20xSmqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mdoel_selection import GriedSearchCV\n",
        "\n",
        "gird = GridSearchCV(모델,\n",
        "                    param_grid = params,  # 미리 지정해둔 파라미터 범위리스트\n",
        "                    scoring = 'roc_auc',  # 사용할 점수\n",
        "                    cv = n,               # 검증할 횟수\n",
        "                    verbose = n           # 검증결과 얼마나 상세하게 볼지(0~3, 3이 제일 상세하게)\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "grid.best_params_    # 최적의 하이퍼파라미터\n",
        "grid.best_score_     # 최적의 검증 점수\n",
        "gird.cv_results_      # 검증 결과 목록"
      ],
      "metadata": {
        "id": "75dqY1MBRmXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randomized Search\n",
        "- 범위로 설정한 값에서 무작위로 추출(횟수는  n_iter x cv의 수만큼만 진행)\n",
        "- 범위가 넓고 빠르지만 모든 조합에 대해 검증하지 않아 가장 이상적인 조합을 발견하지 못할 수 있다.\n",
        "- scipy.stats로 범위를 분포로 지정도 가능\n"
      ],
      "metadata": {
        "id": "Am-7WWQgTDRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.distributions import uniform\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "params = {\n",
        "    \"simpleimpouter__strategy\" : ['median', 'mean']                 # 인코딩, 결측치처리도 가능\n",
        "    \"xgbclassifier__colsample_bytree\" : quniform(0,1, 1, 0.1)       # 범위내에서 step으로 선택 \n",
        "    \"xgbclassifier__colsample_bytree\" : uniform(loc=0.5, scale=0.5) # 0.5 ~ 1 사이에서 랜덤추출\n",
        "}"
      ],
      "metadata": {
        "id": "2G4tvmAwUX5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "randomized = RandomizedSearchCV(\n",
        "    모델,\n",
        "    param_distributioon=params,  # 조정할 하이퍼파라미터\n",
        "    scoring='roc_auc',         \n",
        "    n_iter = n,                  # 돌릴 횟수\n",
        "    cv = n,                      # 검증할 횟수\n",
        "    verbose=n,\n",
        "    random_state=n,\n",
        ")\n",
        "randomized.fit(X_train, y_train)\n",
        "\n",
        "randomized.best_params_   # 최적의 하이퍼파라미터(찾은 값)\n",
        "randomized.best_score_    # 최적의 검증점수\n",
        "\n",
        "randomized.cv_results_    # 하이퍼파라미터 탐색 리스트"
      ],
      "metadata": {
        "id": "4F40aj3DVb3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Search\n",
        "- 검증할 하이퍼파라미터 범위내에서, 이전에 탐색한 조합중 성능이 좋은 조합을 중심으로 확률적으로 탐색\n",
        "- hyperopt 라이브러리로 베지안 서치를 할 수 있다.(단, hyperopt에서 제공하는 범위를 사용해야함)\n",
        "- hyperopt의 fmin는 최종적으로 loss를 가장 작게 만드는 파라미터 조합을 선택(함수를 만들어서 loss와 STATUS값을 제공해야함)\n",
        "- loss이므로 클수록 좋은 함수는 - 부호를 붙여주어야함\n",
        "- fmin의 max_evals 수 만큼 하이퍼파라미터 탐색"
      ],
      "metadata": {
        "id": "uk0PRQAJW5fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperopt 범위 옵션\n",
        "hp.choice('하이퍼파라미터', list or tuple) # 리스트나 튜플의 값을 선택하여 탐색\n",
        "hp.randint('하이퍼파라미터', upper)        #  0 ~ upper 사이의 정수를 랜덤으로 선택\n",
        "hp.uniform('하이퍼파라미터',low, high )    # low ~ high 범위 내의 실수를 랜덤으로 선택\n",
        "hp.quniform('하이퍼파라미터', low, high, q)# low ~ high 사이 균등분포에서 q간격의 지점에서 랜덤수 선택\n",
        "hp.normal('하이퍼파라미터', mu, sigma)     # mu(평균), sigma(표준편차)를 갖는 정규분포 모델에서 실수를 랜덤선택"
      ],
      "metadata": {
        "id": "XamqCWJCYjCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Search순서 : 1. 튜닝할 params작성 / 2.파이프라인구축 함수 / 3. 학습 및 검증 함수 / 4. fmin으로 loss값 받아서 베이지안서치 \n",
        "from hyperopt import hp\n",
        "\n",
        "params= {\n",
        "    \"simpleimputer__strategy\" : hp.choice('strategy', ['mean', 'median']), # 목록에서 랜덤선택\n",
        "    \"xgbclassifier__max_depth\" : hp.quniform(\"max_depth\", 2, 10, 2)        # 2~10 사이에서 2 간격으로 랜덤선택\n",
        "    \"xgblcassifier__colsample_bytree\" : hp.uniform(\"colsample_bytree\", 0.5, 1.0) # 0.5~1.0 사이에서 실수 랜덤선택\n",
        "}"
      ],
      "metadata": {
        "id": "z3QCZC5taPLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, Trials, STATUS_OK\n",
        "from sklearn.model.selection import corss_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "\n",
        "def get_pipe(params): # 파이프라인 구축 함수\n",
        "    params['xgbclassifier__max_depth'] = int(params['xgbclassifier_max_depth']) # 정수형 파라미터로 변경\n",
        "\n",
        "    pipe = make_pipeline(\n",
        "        OrdinalEncoder(),\n",
        "        SimpleImputer(),\n",
        "        XGBClassifier(\n",
        "            random_state = 2,\n",
        "            objective = 'binary:logistic',\n",
        "            eval_metric = 'error',\n",
        "            n_estimators = 20,\n",
        "            learning_rate = 0.2,\n",
        "\n",
        "        ),\n",
        "    )\n",
        "    pipe = pipe.set_params(**params) # parmas의 값을 넣어줌\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def fit_and_eval(params):      # 학습 및 검증 함수\n",
        "    pipe = get_pipe(params)    # 모델 생성\n",
        "    score = cross_val_score(   # 점수 검증\n",
        "        pipe,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv = n,\n",
        "        scoring='roc_auc',\n",
        "    )\n",
        "    avg_cv_score = -np.mean(score) # loss값을 구해야 하므로 높을수록 좋은 값은 -를 붙여줌\n",
        "    return {\"loss\": avg_cv_score, \"status : STATUS_OK\"}  # fmin에 loss와 STATUS 제공\n",
        "\n",
        "trials = (Trials()) # fmin의 trials에 넣어 실행하면 fit의 학습결과를 모두 저장(grid, randomize의 .cv_results_)\n",
        "\n",
        "best_params = fmin(    # hyperopt의 fmin은 loss정보를 얻어서 최적의 하이퍼파라미터 탐색\n",
        "    fn = fit_and_eval, # 학습, 검증 함수\n",
        "    trials = trials,   # 결과를 저장할 객체\n",
        "    space = params,    # 하이퍼파라미터 범위\n",
        "    algo = tpe.suggest,# suggest 알고리즘 사용\n",
        "    max_evals = n      # 탐색 횟수    \n",
        ")"
      ],
      "metadata": {
        "id": "0B-Lit79czZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials.trials # trials에 하이퍼파라미터 탐색 결과 "
      ],
      "metadata": {
        "id": "N5tfsOyuomLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials.best_trial['misc']['vals']    # 최적의 하이퍼파라미터 구성(tiral 목록의 misc의 vals에 저장되어 있음)\n",
        "-trials.best_trial['result']['loss'] # 최적의 하이퍼파라미터의 검증점수(앞에서 - 붙였으니 다시 -붙여줌)"
      ],
      "metadata": {
        "id": "MQzZLBjJozR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 특성선택\n"
      ],
      "metadata": {
        "id": "KGGdO1cBtlIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 직관기반 선택\n",
        "- 데이터가 충분할 때는 예측에 중요하지 않은 특성이 학습데이터에 포함되어 있어도 모델성능에 크게 관여하지 않음(데이터가 적으면 노이즈 과적합이 발생)\n",
        "- 개발자가 주요하지 않은 특성을 선제적으로 배제(추천 알고리즘에서 사용자ID, 이름 등 제거)\n",
        "\n",
        "### 2. 특성중요도기반 선택\n",
        "- 각 특성의 중요도에 따라 특성을 선택\n",
        "- 회귀모델 : model.coef_\n",
        "- 분류모델 : model.feature_importances_"
      ],
      "metadata": {
        "id": "rdowcTputvWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 통계량 기반 특성 선택\n",
        "- 피어슨 상관계수 : 선형성 타겟의 상관관계를 추측(np.corrcoef)\n",
        "- 스피어만 상관계수 : 단조성 타겟의 상관계수를 추측(spearmanr)\n",
        "- SeletKBest : 회귀 or 분류 통계량에 따른 분류\n",
        "   - 분류타겟 옵션 : f_classif / mutual_info_classif / chi2\n",
        "   - 회귀타겟 옵션 : f_regression / mutual_info_regression\n"
      ],
      "metadata": {
        "id": "sldmzGuXvc2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "np.corrcoef(x,y)[0, 1] # 특성 x,y의 선형성 점수\n",
        "spearmanr(x,y)         # 특성 x,y의 단조성 점수"
      ],
      "metadata": {
        "id": "xchSEampu0Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif \n",
        "\n",
        "selector = SelectKBest(score_func = f_classif, k=n)          # 분류문제, 상위 n개의 특성만 사용\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)  # 선택된 n개의 특성으로 훈련데이터 생성\n",
        "X_val_selected = seleector.transform(X_val)                  # 사용할 모델에 model.fit(X_val_selected, y_val)"
      ],
      "metadata": {
        "id": "1_jJOIwSw8WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns[selector.get_support()].tolist()             # SelectKBest에서 선택된 특성 출력"
      ],
      "metadata": {
        "id": "6KUKrVXnyVNb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}