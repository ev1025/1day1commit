# Special Classification Problems
### 불균형한 분류문제에서는 Corr 시각화보다 각 그룹별 평균 타겟을 확인하는게 좋음
#### - 반드시 샘플링 이전에 데이터 분리를 해야함(검증, 테스트 데이터가 샘플링하면 이상한 값이 생성되어 일반화에 오류가 생김)
```python
target = "FraudFound_P"  # 타겟값
df[target].value_counts(normalize=True).plot.pie(autopct="%.3f%%")
print("Baseline Accuracy:", df[target].value_counts(normalize=True).max())
```

### 테스트,검증데이터 auc 확인
```python
import matplotlib.pyplot as plt

results = model.evals_result()
train_error = results["validation_0"]["auc"] # 0로 분류
val_error = results["validation_1"]["auc"]   # 1로 분류

plt.plot(train_error, label="Train")
plt.plot(val_error, label="Validation")
plt.ylabel("ROC-AUC")
plt.xlabel("Model Complexity (n_estimators)")
plt.legend()
```
### 점수들 확인
```python
from sklearn.metrics import classification_report

print("검증 정확도", model.score(X_val_encoded, y_val))

print(
    classification_report(
        y_val, model.predict(X_val_encoded)
    )
)
```
### 점수가 안좋아도 roc auc값이 높게 나올 수 있기 때문에, confusion_matrix 반드시 확인
```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
 

def plot_confusion_matrix(model, X_val_encoded, y_val):
    if isinstance(model, XGBClassifier):
        y_pred = model.predict(X_val_encoded, iteration_range=(0, model.best_iteration))
    else:
        y_pred = model.predict(X_val_encoded)
    cm = confusion_matrix(y_val, y_pred)
    disp = ConfusionMatrixDisplay(cm)        # 컨퓨전 플롯
    disp.plot(cmap='Blues')
    plt.show()
```
### 불균형 해결방법
#### 1. scale_pos_weight : xgboost에서    scale_pos_weight=(y_val == 0).sum() / (y_val == 1).sum() 파라미터 사용   
- 타겟 불균형 문제가 심각 할 경우(99 : 1) np.sqrt(   scale_pos_weight=(y_val == 0).sum() / (y_val == 1).sum())
#### 2. class_weight : sklean 모델에서 class_weight = balanced
#### 3. sampling 
- Undersampling : 다수 클래스의 수를 줄여서 비율을 맞추는 방법(class_weight를 써도 결과가 안좋을 때 사용), 학습데이터가 감소하여 과소적합될 수  있음

```python
!pip install imbalanced-learn
from imblearn.under_sampling import RandomUnderSampler
X_train_sampled, y_train_sampled = RandomUnderSampler(random_state=42).fit_resample(
    X_train_encoded, y_train


```
- Oversampling : 소수 클래스의 수를 늘려서 비율을 맞추는 방법
```python
!pip install imbalanced-learn
from imblearn.over_sampling import SMOTE

X_train_sampled, y_train_sampled = RandomUnderSampler(random_state=42).fit_resample(
    X_train_encoded, y_train
)
```
- Over + Under
```python
!pip install imbalanced-learn
from imblearn.combine import SMOTEENN

X_train_sampled, y_train_sampled = SMOTEENN(random_state=42).fit_resample(
    X_train_encoded, y_train
)
```
#### 4. Ensemble for Imbalanced Dataset
- undersampling과 bagging 함께 사용
- 여러 번 undersampling 한 뒤, 평균을 내어 undersamping의 정보손실을 줄임
```python
!pip install imbalanced-learn
from imblearn.ensemble import BalancedBaggingClassifier

bbc = BalancedBaggingClassifier(base_estimator=model, n_estimators=50, random_state=42)

bbc.fit(X_train_encoded, y_train)
```



### 함수
```python
isinstance(class, dtype)   #class가 dtype이 맞는지? 인자를 bool로 받음 (모델, 모델함수)도 가능 if문에 좋을듯

# xgboost 함수
 iteration_range=(int, int)  # proba 함수  100회 시행할 때 int~ int 회의 결과만 사용
 model.best_iteration     # 모델의 최고값의 차수(0번째 시행값이 최대 값이면 0)
```
 
