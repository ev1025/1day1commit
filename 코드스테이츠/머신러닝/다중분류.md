# Multi-class Classification(다중분류)
### make_classification
- sckit-learn의 분류용 가상 데이터 생성 함수
- 모델의 옵션, 입출력, 포멧에 대한 테스트
```python
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
X, y = make_classification(
    n_samples=1250,          # 샘플개수
    n_features=20,           # 특성개수
    n_informative=12,
    n_classes=4,             # 클래스 개수
    n_clusters_per_class=3,
    random_state=42,
)X_train, X_val, y_train, y_val = train_test_split(
    X, y, stratify=y, train_size=0.8, random_state=42
)```
### 1. Logistic Regression
- 다중분류문제를 해결하기 위해 파라미터 (multi_class = over or multinomial) 사용
    - ovr : 클래스 수만큼 logistic을 사용하여 클래스에 해당되는지 여부를 이진분류로 나타냄
    - multinomial : 클래스 수만큼 logistic을 사용하지만, loss function으로  multinomial cross entropy loss function을 사용(시그모이드 함수 대신 softmax함수 사용) 
- Softmax : softmax 함수는 아래와 같이 정의되며, 각 class에 속할 확률을, 각 class에 대해 0~1사이 값이 되고 전체 합이 1이 되도록 만들어 주는 함수
```python
import numpy as np
def softmax(x):
    return np.exp(x) / np.exp(x).sum()
print(softmax(np.array([1.2, 0.8, -1.8, -0.3])))
>>>
[0.5146052  0.34495018 0.02562068 0.11482394] # 각 클래스에 속할 확률 도합 1
```
### 2. Tree-based Model
- 지니불순도와 엔트로피가 다중 class 상황에서도 지원됨
## 다중분류 평가지표
1. Accuray(정확도)
```python
from sklearn.metrics import accuracy_score
# accuracy = (y_val == y_pred).sum() / len(y_pred) # 전체 샘플대비 예측수
print("Accuracy:", accuracy_score(y_val, rf.predict(X_val)))
```
2. Confusion Matrix(대각선에 있는값들)
```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
sns.heatmap(confusion_matrix(y_val, rf.predict(X_val)), annot=True, fmt="g")
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.show()
```
![다운로드](https://user-images.githubusercontent.com/110000734/191881219-64229cac-24e9-49d3-874e-46669fad2c21.png)
3. F1-score
- 이진 클래스에서 F1-score는 아래와 같이 계산됩니다.
$$ F1 = \frac{TP}{TP + (FP + FN) / 2} $$
- 다중 클래스에서는 각 클래스별로 TP, TN, FP, FN이 정의됩니다.
![5GhBzyA](https://user-images.githubusercontent.com/110000734/191881288-d7ae2d7c-b90d-4337-82e2-e4e6bf6db2fc.png)
- 다중 클래스에서의 F1-score는 `micro`, `macro`, `weighted`의 세 가지 방법으로 계산될 수 있습니다.
  - `micro`: 최종 TP, TN, FP, FN을 각 class의 TP, TN, FP, FN 각각의 합으로 정의합니다. 이후 F1을 계산합니다(이는 `Accuracy`와 같은 값을 갖게 됩니다).
  - `macro`: 각 class의 TP, TN, FP, FN을 사용해 class별로 F1을 구한 후, 이를 단순평균합니다.
  - `weighted`: 각 class의 TP, TN, FP, FN을 사용해 class별로 F1을 구한 후, 이를 각 class에 속하는 데이터의 수로 가중평균합니다.
```python
from sklearn.metrics import f1_score
print("F1-micro:", f1_score(y_val, rf.predict(X_val), average="micro"))
print("F1-macro", f1_score(y_val, rf.predict(X_val), average="macro"))
print("F1-weighted", f1_score(y_val, rf.predict(X_val), average="weighted"))
>>>
F1-micro: 0.692
F1-macro 0.6904848948568588
F1-weighted 0.6902244070988
```
4. Classification Report
```python
from sklearn.metrics import classification_report
print(classification_report(y_val, rf.predict(X_val)))
>>>
              precision    recall  f1-score   support
           0       0.69      0.75      0.72        63
           1       0.76      0.73      0.74        62
           2       0.67      0.74      0.70        62
           3       0.65      0.56      0.60        63
    accuracy                           0.69       250
   macro avg       0.69      0.69      0.69       250
weighted avg       0.69      0.69      0.69       250
```
