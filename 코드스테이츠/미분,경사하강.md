# 미분 (derivative)

### 미분 방법
```python
∫(인테그랄) : 적분, 무수히 많은 변화들을 더하는 것, 뒤에는 항상 d(변화량)
∑ : 비연속적 적분

d : 미분, 변화량
∆ : 비연속적 미분

x**2 미분-> d(x**2) = 2x * dx

f(x) = e**x 미분 -> f`(x) = e**x  ( 변화없음)  # 지수함수 math.exp(1) = e

f(x) = lnx 미분 -> f`(x) = 1/x

f(x) = a(x**n) 미분 ->f`(x) = a*n*x**(n-1)

편미분(Partial Derivative)
- 파라미터가 2개 이상인 함수에서 1개의 변수를 제외한 변수는 상수취급 하는 것
Chain rules
f(x) = (x**4 + 3x + 2)**3을 미분하면 (x**4+3x+2)**2 *(4x**3+3)
```
![chainrule](https://user-images.githubusercontent.com/110000734/185942861-7f4b853c-5030-424d-8048-869168327bc9.JPG)
![KakaoTalk_20220901_153614774](https://user-images.githubusercontent.com/110000734/187847871-c25ab388-8b01-4ff1-a6c4-08137c60b74e.jpg)



### 경사하강법 (Gradient Descent)
- 예측값과 실제값 사이의 에러를 나타내는 오차함수J(@,@)
- 오차함수가 낮아지는 방향으로 독립변수 @1,@2를 변형시켜 최소값을 찾는 것
- 즉, 경사하강법은 오차함수의 최소값의 독립변수값을 찾는 방법
- learning rate를 너무 적게도 너무 크게도 잡으면 안됨(최소값을 넘어갈 수 있기 때문에)

### 경사하강 알고리즘 과정
1. 임의의 파라미터 2개를 랜덤으로 선택
2. 반복적으로 파라미터를 업데이트하며 오차함수 값이 낮아지는 방향으로 진행
3. 이때 기울기( ∇J(@))는 항상 오차 함수값(cost function)이 더 크게 감소하는 방향으로 진행
4. 수학공식 @n+1 = @n – (학습률 * 기울기 * J(@n)) # 기울기에 –를 곱해 반대반향
5. 학습률(Learning Rate)은 극소값을 지나칠 수 있기 때문에 적당한 속도로 지정해야함

### 미분의 활용
- Before minimum : 기울기가 –일 때 최소 값의 방향은 +
- After minimum : 기울기가 +일 때 최소 값의 방향은 -
- global minimum : 기울기가 최소값인 지점

#### Linear Regression( 단순회귀 모형에서의 경사하강)
1. y = @1x +@0      # @0 = y절편(intercept) ,@1 = 기울기
2. 단순 회귀 모형은 y절편과 기울기에 의해 모양이 형성된다.
3. 오차함수 J(@) = (실제값 – 예측값)^2 = 오차거리를 데이터 전체 수로 나눠주는 것(Mean Squared Error방법)
![오차함수](https://user-images.githubusercontent.com/110000734/185940074-6c878fff-a290-40ba-b7d4-9e8973fb576f.JPG)

4. 선형회귀는 local minimum이 존재하지 않음


## 오늘의 함수
```python
df[‘columns’] = df.apply(함수명) # 함수의 값(x)을 df에서 받아서 새컬럼에 저장, 1번만 가능 두번 하면 오류남(딕셔너리는 1개만 가질 수 있다고 함)

df[‘columns’] = df.derivative(함수명, x, dx=e값) # 함수의 식을 미분(dx값 exp 안쓰고 e로 써도 됨), x 값이 컬럼에 있을땐 df[‘x’] 해줄 것

math,exp(숫자), np.exp(숫자), np.e   # 지수 e값

df = derivative(함수명, x, dx = e~)  # 함수 미분

df.subs(x,1)
df.subs({x:1,y:2})                   # 각 x,y에 값을 대입

import sympy as sp
x, y = sp.symbols(‘x y’)            # x와 y를 변수로 지정 / f = sp.symbols('f', cls=sp.Function) 함수명(f)도 지정가능

f(x) = x
sp.diff(f, x)                       # f(x)를 미분 ,f`는 함수f의 x에 대한 도함수(기울기)

sp.solve(방정식, x)                  # 방정식의 x의 해 구하기(편미분에서 x값 구할 때), 값이 []로 반횐되서 뒤에 [0] 인덱스 적용해야함

xy`+y = 2x
eq = sp.Eq(x * diff(y,x) + y, 2*x)   # Eq의 ,를 기준으로 좌변, 우변 식 저장
```
